<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AWS DataLab 智能货架 on SpotBot Workshop</title><link>/</link><description>Recent content in AWS DataLab 智能货架 on SpotBot Workshop</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Fri, 05 Nov 2021 14:52:27 +0800</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml"/><item><title>1.1 算法概述</title><link>/01introduction/100algorithm.html</link><pubDate>Fri, 05 Nov 2021 14:52:27 +0800</pubDate><guid>/01introduction/100algorithm.html</guid><description>使用场景 根据生成检测框方法不同可以分为Anchor Free方法和Anchor Based方法，而Anchor Based又可以进一步分为One-Stage方法和Two-Stage方法。
One-Stage：Yolo、SSD、RetinaNet。 Two-Stage：RCNN、Faster RCNN、FPN。 随着2012年AlexNet的出现，越来越多的领域被深度学习屠榜，而目标检测这个停滞多年的视觉领域也重新焕发的活力。目标检测的研究成果在计算机视觉三大顶会（CVPR/ICCV/ECCV）的占比也逐年增加。
本workshop主要覆盖以下几个算法，对比结果如下
Pegasus BART</description></item><item><title>1.2 卷积神经网络(CNN)及其理解</title><link>/01introduction/cnn.html</link><pubDate>Fri, 05 Nov 2021 14:52:27 +0800</pubDate><guid>/01introduction/cnn.html</guid><description>卷积神经网络基础 计算机眼中的图像： 单层卷积操作： 卷积神经网络(Convolutional Neural Network, CNN)： 通过可视化理解卷积神经网络 浅层卷积核以及特征图可视化：底层卷积层的卷积核负责提取低级特征：如颜色，纹理等等 层数加深，特征不断精细化： 深层卷积核以及特征图可视化：最终高层卷积核所对应的特征十分具体且方便分类
CNN学习到的特征呈现分层特性，底层是一些边缘角点以及颜色的抽象特征，越到高层则越呈现出具体的特征，这一过程正与人类视觉系统类似。故更多的模型向更深的卷积层发展，这也是深度学习的“深”的确切含义</description></item><item><title>1.3 评估指标</title><link>/01introduction/300metrics.html</link><pubDate>Fri, 05 Nov 2021 14:52:27 +0800</pubDate><guid>/01introduction/300metrics.html</guid><description>目标检测由于涉及到多个子任务：定位，分类。故其评价方法较为复杂，本章从交并比，准确率，精度，召回率，FPR, F1-Score, PR曲线，ROC曲线，AP的值，AUC的值以及很重要的mAP指标，模型的检测速度和非极大值抑制的相关方面来学习下目标检测中的评价指标。
交并比 — IoU 交并比IoU是英文intersection over union的简写，意思是检测结果的矩形框与样本标注的矩形框的交集与并集的比值。如下图： 上图中假设A为模型的检测结果，B为Ground Truth即样本的标注结果，那么A与B相交的区域即为A∩B，而A与B的并集即为AB共有的区域A∪B,那么IoU的计算公式即为: IoU = (A∩B) / (A∪B)
一般情况下对于检测框的判定都会存在一个阈值，也就是IoU的阈值，一般可以设置当IoU的值大于0.5的时候，则可认为检测到目标物体。
准确率/精度/召回率/FPR/F1指标 以上五个指标都离不开下列定义：
预测值为正例，记为P（Positive） 预测值为反例，记为N（Negative） 预测值与真实值相同，记为T（True） 预测值与真实值相反，记为F（False） 准确率 准确率accuracy是我们最常见的评价指标，这个很容易理解，就是被分对的样本数除以所有的样本数，通常来说，正确率越高，分类器越好，如下：
accuracy = (TP+TN)/(TP+TN+FP+FN) 上公式中的TP+TN即为所有的正确预测为正样本的数据与正确预测为负样本的数据的总和，TP+TN+FP+FN即为总样本的个数。
精度 精度precision是从预测结果的角度来统计的，是说预测为正样本的数据中，有多少个是真正的正样本，即“找的对”的比例，如下：
precision = TP/( TP+FP) 上公式中的TP+FP即为所有的预测为正样本的数据，TP即为预测正确的正样本个数。
召回率/TPR 召回率recall和TPR(灵敏度(true positive rate))是一个概念，都是从真实的样本集来统计的，是说在总的正样本中，模型找回了多少个正样本，即“找的全”的比例，如下：
recall/TPR = TP/(TP+FN) 上公式中的TP+FN即为所有真正为正样本的数据，而TP为预测正确的正样本个数。
FPR FPR(false positive rate)，它是指实际负例中，错误的判断为正例的比例，这个值往往越小越好，如下：
FPR = FP/(FP+TN) 其中，FP+TN即为实际样本中所有负样本的总和，而FP则是指判断为正样本的负样本。
F1-Score F1分数(F1-score)是分类问题的一个衡量指标。F1分数认为召回率和精度同等重要, 一些多分类问题的机器学习竞赛，常常将F1-score作为最终测评的方法。它是精确率和召回率的调和平均数，最大为1，最小为0。计算公式如下：
F1 = 2TP/(2TP+FP+FN) 此外还有F2分数和F0.</description></item></channel></rss>